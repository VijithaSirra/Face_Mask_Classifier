{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor   = tf.placeholder(shape=(None, 64, 64, 3), dtype=\"float32\", name=\"input_tensor\")\n",
    "output_tensor  = tf.placeholder(shape=(None, 2), dtype=\"float32\", name=\"output_tensor\")\n",
    "bn_tensor      = tf.placeholder(tf.bool,shape=None)\n",
    "dropout_tensor = tf.placeholder(shape=(None), dtype=\"float32\", name = \"Dropout\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "layer_1 = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3), strides = (2, 2))(input_tensor)\n",
    "layer_2 = tf.keras.layers.BatchNormalization()(layer_1, training = bn_tensor)\n",
    "layer_3 = tf.keras.layers.ReLU()(layer_2)\n",
    "layer_3 = tf.keras.layers.Dropout(rate = dropout_tensor)(layer_3)\n",
    "layer_4 = tf.keras.layers.Conv2D(filters = 32, kernel_size = (1,1), strides = (1,1))(layer_3)\n",
    "layer_5 = tf.keras.layers.BatchNormalization()(layer_4, training = bn_tensor)\n",
    "layer_6 = tf.keras.layers.ReLU()(layer_5)\n",
    "layer_6 = tf.keras.layers.Dropout(rate = dropout_tensor)(layer_6)\n",
    "\n",
    "\n",
    "layer_7  = tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3), strides = (2, 2))(layer_6)\n",
    "layer_8  = tf.keras.layers.BatchNormalization()(layer_7,training = bn_tensor)\n",
    "layer_9  = tf.keras.layers.ReLU()(layer_8)\n",
    "layer_9  = tf.keras.layers.Dropout(rate = dropout_tensor)(layer_9)\n",
    "layer_10 = tf.keras.layers.Conv2D(filters = 64, kernel_size = (1,1), strides = (1,1))(layer_9)\n",
    "layer_11 = tf.keras.layers.BatchNormalization()(layer_10, training = bn_tensor)\n",
    "layer_12 = tf.keras.layers.ReLU()(layer_11)\n",
    "layer_12 = tf.keras.layers.Dropout(rate = dropout_tensor)(layer_12)\n",
    "\n",
    "\n",
    "layer_13 = tf.keras.layers.Conv2D(filters = 128, kernel_size = (3,3), strides = (1, 1))(layer_12)\n",
    "layer_14 = tf.keras.layers.BatchNormalization()(layer_13, training = bn_tensor)\n",
    "layer_15 = tf.keras.layers.ReLU()(layer_14)\n",
    "layer_15 = tf.keras.layers.Dropout(rate = dropout_tensor)(layer_15)\n",
    "layer_16 = tf.keras.layers.Conv2D(filters = 128, kernel_size = (1,1), strides = (1,1))(layer_15)\n",
    "layer_17 = tf.keras.layers.BatchNormalization()(layer_16, training = bn_tensor)\n",
    "layer_18 = tf.keras.layers.ReLU()(layer_17)\n",
    "layer_18 = tf.keras.layers.Dropout(rate = dropout_tensor)(layer_18)\n",
    "\n",
    "\n",
    "layer_19 = tf.keras.layers.Conv2D(filters = 256, kernel_size = (3,3), strides = (2, 2))(layer_18)\n",
    "layer_20 = tf.keras.layers.BatchNormalization()(layer_19, training = bn_tensor)\n",
    "layer_21 = tf.keras.layers.ReLU()(layer_20)\n",
    "layer_21 = tf.keras.layers.Dropout(rate = dropout_tensor)(layer_21)\n",
    "layer_22 = tf.keras.layers.Conv2D(filters = 256, kernel_size = (1,1), strides = (1,1))(layer_21)\n",
    "layer_23 = tf.keras.layers.BatchNormalization()(layer_22, training = bn_tensor)\n",
    "layer_24 = tf.keras.layers.ReLU()(layer_23)\n",
    "layer_24 = tf.keras.layers.Dropout(rate = dropout_tensor)(layer_24)\n",
    "\n",
    "layer_25 = tf.keras.layers.AveragePooling2D(pool_size= 6, strides =1)(layer_24) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_26 = tf.keras.layers.Dense(units= 2)(layer_25)\n",
    "layer_27 = tf.reshape(layer_26,shape = (-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2d/BiasAdd:0\", shape=(?, 31, 31, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization/cond/Merge:0\", shape=(?, 31, 31, 32), dtype=float32)\n",
      "Tensor(\"dropout_1/cond/Merge:0\", shape=(?, 31, 31, 32), dtype=float32)\n",
      "Tensor(\"conv2d_1/BiasAdd:0\", shape=(?, 31, 31, 32), dtype=float32)\n",
      "Tensor(\"batch_normalization_1/cond/Merge:0\", shape=(?, 31, 31, 32), dtype=float32)\n",
      "Tensor(\"dropout_1_1/cond/Merge:0\", shape=(?, 31, 31, 32), dtype=float32)\n",
      "Tensor(\"conv2d_2/BiasAdd:0\", shape=(?, 15, 15, 64), dtype=float32)\n",
      "Tensor(\"batch_normalization_2/cond/Merge:0\", shape=(?, 15, 15, 64), dtype=float32)\n",
      "Tensor(\"dropout_2/cond/Merge:0\", shape=(?, 15, 15, 64), dtype=float32)\n",
      "Tensor(\"conv2d_3/BiasAdd:0\", shape=(?, 15, 15, 64), dtype=float32)\n",
      "Tensor(\"batch_normalization_3/cond/Merge:0\", shape=(?, 15, 15, 64), dtype=float32)\n",
      "Tensor(\"dropout_3/cond/Merge:0\", shape=(?, 15, 15, 64), dtype=float32)\n",
      "Tensor(\"conv2d_4/BiasAdd:0\", shape=(?, 13, 13, 128), dtype=float32)\n",
      "Tensor(\"batch_normalization_4/cond/Merge:0\", shape=(?, 13, 13, 128), dtype=float32)\n",
      "Tensor(\"dropout_4/cond/Merge:0\", shape=(?, 13, 13, 128), dtype=float32)\n",
      "Tensor(\"conv2d_5/BiasAdd:0\", shape=(?, 13, 13, 128), dtype=float32)\n",
      "Tensor(\"batch_normalization_5/cond/Merge:0\", shape=(?, 13, 13, 128), dtype=float32)\n",
      "Tensor(\"dropout_5/cond/Merge:0\", shape=(?, 13, 13, 128), dtype=float32)\n",
      "Tensor(\"conv2d_6/BiasAdd:0\", shape=(?, 6, 6, 256), dtype=float32)\n",
      "Tensor(\"batch_normalization_6/cond/Merge:0\", shape=(?, 6, 6, 256), dtype=float32)\n",
      "Tensor(\"dropout_6/cond/Merge:0\", shape=(?, 6, 6, 256), dtype=float32)\n",
      "Tensor(\"conv2d_7/BiasAdd:0\", shape=(?, 6, 6, 256), dtype=float32)\n",
      "Tensor(\"batch_normalization_7/cond/Merge:0\", shape=(?, 6, 6, 256), dtype=float32)\n",
      "Tensor(\"dropout_7/cond/Merge:0\", shape=(?, 6, 6, 256), dtype=float32)\n",
      "Tensor(\"average_pooling2d/AvgPool:0\", shape=(?, 1, 1, 256), dtype=float32)\n",
      "Tensor(\"dense/BiasAdd:0\", shape=(?, 1, 1, 2), dtype=float32)\n",
      "Tensor(\"Reshape:0\", shape=(?, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(layer_1)\n",
    "print(layer_2)\n",
    "print(layer_3)\n",
    "print(layer_4)\n",
    "print(layer_5)\n",
    "print(layer_6)\n",
    "print(layer_7)\n",
    "print(layer_8)\n",
    "print(layer_9)\n",
    "print(layer_10)\n",
    "print(layer_11)\n",
    "print(layer_12)\n",
    "print(layer_13)\n",
    "print(layer_14)\n",
    "print(layer_15)\n",
    "print(layer_16)\n",
    "print(layer_17)\n",
    "print(layer_18)\n",
    "print(layer_19)\n",
    "print(layer_20)\n",
    "print(layer_21)\n",
    "print(layer_22)\n",
    "print(layer_23)\n",
    "print(layer_24)\n",
    "print(layer_25)\n",
    "print(layer_26)\n",
    "print(layer_27)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = layer_27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=output_tensor, logits=prediction) # tf.reduce_mean(tf.squared_difference(output_tensor, prediction))\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.arg_max(prediction, 1), tf.arg_max(output_tensor, 1)), \"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    loss_optimization = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Train Images :  5000\n",
      "No of Test Images  :  1000\n"
     ]
    }
   ],
   "source": [
    "images_list = []\n",
    "for root, folder, files in os.walk(\"/home/grace/Projects/FaceMask_Detection/Dataset/\"):\n",
    "    for file in files :\n",
    "        images_list.append(root + file)\n",
    "images_list , test = images_list[0:5000] , images_list[5000:6000]\n",
    "print(\"No of Train Images : \", len(images_list))\n",
    "print(\"No of Test Images  : \", len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess= tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 Loss 1.072  Train Accuracy : 0.503  Test Accuracy : 1.0\n",
      "Time Takes For This Epoch is :  42.48396897315979\n",
      "******************************************************\n",
      "Epoch : 1 Loss 0.0  Train Accuracy : 1.0  Test Accuracy : 1.0\n",
      "Time Takes For This Epoch is :  89.1093327999115\n",
      "******************************************************\n",
      "Epoch : 2 Loss 0.0  Train Accuracy : 1.0  Test Accuracy : 1.0\n",
      "Time Takes For This Epoch is :  89.47548246383667\n",
      "******************************************************\n",
      "Epoch : 3 Loss 0.0  Train Accuracy : 1.0  Test Accuracy : 1.0\n",
      "Time Takes For This Epoch is :  89.15962290763855\n",
      "******************************************************\n",
      "Epoch : 4 Loss 0.0  Train Accuracy : 1.0  Test Accuracy : 1.0\n",
      "Time Takes For This Epoch is :  85.88146543502808\n",
      "******************************************************\n",
      "Epoch : 5 Loss 0.0  Train Accuracy : 1.0  Test Accuracy : 1.0\n",
      "Time Takes For This Epoch is :  69.39099478721619\n",
      "******************************************************\n",
      "Epoch : 6 Loss 0.0  Train Accuracy : 1.0  Test Accuracy : 1.0\n",
      "Time Takes For This Epoch is :  81.28331351280212\n",
      "******************************************************\n",
      "Epoch : 7 Loss 0.0  Train Accuracy : 1.0  Test Accuracy : 1.0\n",
      "Time Takes For This Epoch is :  75.16332817077637\n",
      "******************************************************\n",
      "Epoch : 8 Loss 0.0  Train Accuracy : 1.0  Test Accuracy : 1.0\n",
      "Time Takes For This Epoch is :  68.33356738090515\n",
      "******************************************************\n",
      "Epoch : 9 Loss 0.0  Train Accuracy : 1.0  Test Accuracy : 1.0\n",
      "Time Takes For This Epoch is :  65.89243793487549\n",
      "******************************************************\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch = 20\n",
    "total_images = len(images_list)\n",
    "test_images = len(test)\n",
    "for epoch in range(num_epochs):\n",
    "    t1 = time.time()\n",
    "    acc_list = []\n",
    "    loss_list = []\n",
    "    test_acc_list = []\n",
    "    for i in range(0, total_images-batch, batch):\n",
    "        image_batch = []\n",
    "        label_batch = []\n",
    "        for image in images_list[i:i+batch]:\n",
    "            single_image = cv2.imread(image)/255.0 - 0.5\n",
    "            single_image = cv2.resize(single_image, (64, 64))\n",
    "            image_batch.append(single_image)\n",
    "            label = int(image.split(\"/\")[-1].split(\"_\")[0])\n",
    "            label_batch.append(np.eye(2)[label])\n",
    "        label_batch = np.array(label_batch, dtype=np.float32)\n",
    "        \n",
    "        if epoch == 0:            \n",
    "            acc, loss_val = sess.run([accuracy, loss], \\\n",
    "                                     feed_dict={input_tensor :image_batch, output_tensor : label_batch, \\\n",
    "                                               bn_tensor : False, dropout_tensor : 0.0 })\n",
    "            acc_list.append(acc)\n",
    "            loss_list.append(loss_val)\n",
    "        else : \n",
    "            opt, acc, loss_val = sess.run([loss_optimization, accuracy, loss], \\\n",
    "                                          feed_dict={input_tensor :image_batch, output_tensor : label_batch, \\\n",
    "                                                    bn_tensor : True, dropout_tensor : 0.2 })\n",
    "            acc_list.append(acc)\n",
    "            loss_list.append(loss_val)\n",
    "    for j in range(0, test_images-batch, batch):\n",
    "        test_image_batch = []\n",
    "        test_label_batch = []\n",
    "        for test_image in test[j:j+batch]:\n",
    "            single_test_image = cv2.imread(test_image)/255.0 - 0.5\n",
    "            single_test_image = cv2.resize(single_test_image, (64, 64))\n",
    "            test_image_batch.append(single_test_image)\n",
    "            test_label = int(test_image.split(\"/\")[-1].split(\"_\")[0])\n",
    "            test_label_batch.append(np.eye(2)[test_label])\n",
    "        test_label_batch = np.array(test_label_batch, dtype=np.float32)\n",
    "        \n",
    "        test_acc = sess.run([accuracy], \\\n",
    "                            feed_dict={input_tensor :test_image_batch, output_tensor : test_label_batch, \\\n",
    "                                      bn_tensor : True, dropout_tensor : 0.0 })\n",
    "        test_acc_list.append(test_acc)\n",
    "        \n",
    "    print(\"Epoch : \" + str(epoch) + \" Loss \" +  str(round(np.average(loss_list), 3)) + \\\n",
    "          \"  Train Accuracy : \" + str(round(np.average(acc_list), 3)) + \"  Test Accuracy : \" + \\\n",
    "          str(round(np.average(test_acc_list), 3)))\n",
    "    print(\"Time Takes For This Epoch is : \", time.time() - t1)\n",
    "    print(\"******************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Face_Mask_Classifier/TF_Model'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess,'./Face_Mask_Classifier/TF_Model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 50 variables.\n",
      "INFO:tensorflow:Converted 50 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "frozen_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "    sess,\n",
    "    sess.graph_def,\n",
    "    [\"Reshape\"])\n",
    "\n",
    "with open('./Face_Mask_Classifier/TF_FrozenModel.pb', 'wb') as f:\n",
    "    f.write(frozen_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'output_tensor:0' shape=(?, 2) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
